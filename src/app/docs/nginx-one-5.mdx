---
title: NGINX One Console Lab - NGINX Instance Management
description: Do the NGINX Instance Management Use Case Lab
order: 5
---

## Use Case 1: NGINX Instance Management

This lab will detail the use case for adding NGINX Instances to the NGINX One Console. Below is a system diagram diagram
showing this interaction can be seen below.

![](media/upskill/presentation-4.png)


## Lab Introduction

This lab will give you an overview of how the NGINX One console provides visibility into a global fleet of NGINX
instances, both NGINX Plus and NGINX Open Source (OSS).

After this lab, you will be able to:

- Manage and update NGINX configuration from NGINX One Console
  - Publish changes
  - Enable TLS
- Review recommendations from the NGINX One console
- Install the NGINX Agent on both NGINX Plus and NGINX OSS instances

## Prerequisites

The "NGINX One Enablement Lab" UDF blueprint contains all the prerequisites for this lab. This includes:

- This interactive lab guide
- NGINX Plus and NGINX OSS instances
- F5 XC [lab tenant](https://f5-xc-lab-app.console.ves.volterra.io) access

> Tip: Clicking on any image in this lab guide lab will enlarge it. To dismiss the enlarged image, click the white "X"
in its window, or press the Escape key.

## Demo lab

I will now do a demo lab. The instructions I am going though is here. You can watch me go thought the demo or follow
along with me.

## Interactive lab

Now lets continue to the interactive lab where you will be learn how to add NGINX instances to NGINX One Console.

### Connecting to the Console

The NGINX One Console uses an agent installed alongside NGINX instances to communicate with it.

The agent uses a **Data Plane Key** to authenticate and identify itself to NGINX One Console. In this lab we will create
a new **Data Plane Key**, and use it to install the NGINX Agent on the NGINX Instance.

### Generating a Data Plane Key

1. From the NGINX One Console, in the left hand menu under the "Manage" section, select **Data Plane Keys**.

1. Click **Add Data Plane Key**.

1. Give the key a name based on your lab's ephemeral name, such as **<GetVariable name="petname" />-nginx-key**.

    > :point_right: **Note:** You are working in a shared environment; keep track of your resources, and be careful not
    to accidentally modify anyone else's.

1. By default, the key expiration date will be set to 1 year.  Depending on your use case, you may want to set a shorter
expiration date.  For this lab, we will use the default value.

1. Click **Generate**.

    ![Generating a Data Plane Key](media/lab2-4.png)

1. The Data Plane Key will be displayed. Click the *Copy* icon to copy the key to the clipboard.

    > :warning: **Warning:** *SAVE THIS KEY SOMEWHERE SAFE.* There is no way to retrieve the key after you click
    **Close**. This key will be used in multiple labs.

    ![Data Plane Key](media/lab2-5.png)

## NGINX OSS (Open Source)

The NGINX One Console supports both NGINX Plus and NGINX OSS. Both products leverage the NGINX Agent to communicate with
the NGINX One Console API. The UDF blueprint contains a Ubuntu host with the package maintainerâ€™s version of NGINX OSS
installed.  In this section we will install NGINX Agent and connect this instance to the NGINX One Console.

### Installing NGINX Agent on NGINX OSS

1. Connect to the "NGINX OSS" instance in UDF through the Web Shell access method by clicking the *Open Web Shell* button below:

> TODO: ADD WebShell

1. Because the hostname is used as the name of the instance in the NGINX One Console, you should change the hostname to
something that identifies it as yours, such as **<GetVariable name="petname" />-ubuntu-oss**. Ensure that you are 
working on the NGINX OSS instance (default hostname ip-10.1.1.6), and run the following command.

    > **Note:** The bash prompt will continue to show the previous hostname unless you log out and log back in. This
    does not affect the lab.

    ```bash
    sudo hostnamectl set-hostname {{petname}}-ubuntu-oss
    ```

1. From the NGINX One Console, navigate to **Instances** under the Manage section on the left.

    ![Instance](media/upskill/use-case-1/1.png)

1. Select **Add Instance**.

    ![Instance](media/upskill/use-case-1/2.png)

1. Because we created a **Data Plane Key** in the previous step, select **Use existing Key** ->
provide your Data Plane Key from the previous step -> Ensure **Virtual Machine or Bare Metal** tab is selected -> Copy
the example command by select the copy button.

    ![Instance](media/upskill/use-case-1/3.png)

1. Go to the **Web Shell** of your NGINX OSS instance and run the command you just copied. Below is an example output.

    ![Instance](media/upskill/use-case-1/4.png)

   The install script will install any necessary dependencies, and install the NGINX Agent with the appropriate settings for your system. You will see a warning about "stub_status" not being configured. You can ignore that warning.

1. Return to the NGINX One console. From the left menu in the Manage section, click Instances. You should see your new instance in the list.

    ![Instance](media/upskill/use-case-1/5.png)

1. Click its hostname to view the instance details.

    ![Instance list](media/optional1-1.png)

1. Explore the instance details.

    ![Instance Details](media/optional1-2.png)

    Note that this instance has a different set of configuration recommendations than the vanilla NGINX Plus instance
    did. Package maintainers may ship NGINX with their own sets of defaults, which may or may not align with best
    practices. NGINX One Console provides a centralized view of such recommendations across the organization.

1. You now successfully added an NGINX Open Source instance to NGINX One Console.

### Viewing Logs

Logs that contain information relating to the connection between this instance and NGINX One Console can be found in
the NGINX agent logs located at **/var/log/nginx-agent** from the NGINX instance.

1. From your Web Shell of your NGINX OSS instance, you can view the logs using the following command.

    ``` bash
    less /var/log/nginx-agent/agent.log
    ```

1. Here is a snippet of what you may see

    ![Instance](media/upskill/use-case-1/6.png)

## NGINX Docker

Now that we've added an NGINX instance that is on a Virtual Machine, we will now try adding an NGINX container instance.

The **Lab Framework** from the UDF environment has **docker** installed and is setup so it can run an NGINX Plus
container image. The container image we will use here is **private-registry.nginx.com/nginx-plus/agent:debian** which 
has NGINX Plus with the Agent. If you want to see a list of all NGINX Plus with Agent tags, refer to the
[documentation](https://docs.nginx.com/nginx/admin-guide/installing-nginx/installing-nginx-docker/#pulling-the-image).

1. Go to *Instances* under *Manage* and click *Add Instance*.

1. Select *Use existing Key* because you already created one from earlier.

1. Provide your Data Plane Key.

1. Select the *Docker Container* tab.

    ![Add New NGINX Plus Container](media/lab5-17.png)

    > **Note:** This system already cached the container image, so Steps 1 and 2 from above can be skipped.

1. Open a Web Shell to the **Lab Framework** UDF instance and start an NGINX Plus container with the commands below.

1. Because we are using a shared XC tenant, we will be modifying the command from Step 3 so you can distinguish your
NGINX container instance from others. Run the *docker run* command outlined in Step 3 to start the NGINX Plus with Agent
container. Replace YOUR_DATA_PLANE_KEY with your Data Plane Key.

    ```shell
    sudo docker run --hostname={{petname}}-nginx-plus-manual --name={{petname}}-nginx-plus-manual \
    --env=NGINX_AGENT_SERVER_GRPCPORT=443 \
    --env=NGINX_AGENT_SERVER_HOST=agent.connect.nginx.com \
    --env=NGINX_AGENT_TLS_ENABLE=true \
    --env=NGINX_AGENT_TLS_SKIP_VERIFY=false \
    --restart=always \
    --runtime=runc \
    --env=NGINX_AGENT_SERVER_TOKEN=YOUR_DATA_PLANE_KEY \
    -d private-registry.nginx.com/nginx-plus/agent:debian
    ```

1. Click *Done* to close the window.

1. Return to the NGINX One console. From the left menu in the Manage section, click Instances. You should see your new instance in the list.


### Viewing Logs

Now let's take a look at the NGINX agent logs. The logs can be examined by connecting to the container.

1. Start an interactive Bash shell session inside the specified container

    ``` bash
    docker exec -it YOUR_CONTAINER_ID /bin/bash
    ```

1. Use the following command to view the NGINX Agent logs in real time.

    ``` bash
    tail -f /var/log/nginx-agent/agent.log
    ```

## Console Overview

Now that we have set up our data plane key and deployed our NGINX instances we can take a look around the NGINX One Console:

1. Return to the NGINX One Console. From the left menu in the *Manage* section, click *Instances*.

1. You should see your **<GetVariable name="nginx-plus-1" />** instance in the list, click on it to view the instance details.

    ![NGINX One Instance List](media/lab2-7.png)

### Explore the instance details

The NGINX One Console provides several key metrics for us to evaluate:

    - Instance Certificates
    - Instance CVEs
    - Configuration Recommendations
    - Instance Details

    ![NGINX Plus instance details](media/lab2-8.png)

#### Instance Certificates

The NGINX One Console displays the number of certificates currently installed on the NGINX instance as well as the current status of the certificates, expiration date,
and the certificate's *Subject Name*.

We'll get to explore this in greater detail later in the lab when we install a SSL/TLS certificate.

#### Instance CVEs

The NGINX One Console displays the number of CVEs associated with the NGINX instance as well as their severity.  You can also find out more information about each CVE
with a link to the CVE Program website with extensive details about the CVE in question.

#### Configuration Recommendations

The NGINX One Console will evaluate the NGINX instance configuration and provide recommendations based on best practices and security concerns.
We'll get to explore this in greater detail later in the lab when we configure the stub_status location.

#### Instance Details

The NGINX One Console also provides various details about the NGINX instance such as:

    | Instance Type | Description |
    | --- | --- |
    | Availability | The availability status of the NGINX instance |
    | Data Plane Key | The data plane key associated with the NGINX instance |
    | Hostname | The hostname of the NGINX instance |
    | Last Seen | The last time the NGINX instance was seen |
    | NGINX Agent Version | The version of the NGINX Agent running on the instance |
    | NGINX Config Path | The path to the NGINX configuration file |
    | Operating System | The operating system running on the instance |
    | Registration Time | The time when the NGINX instance was registered |
    | Instance Type | The type of the NGINX instance |

### Explore NGINX One dashboard

The NGINX One Dashboard provides an at-a-glance view of metrics and findings about your global NGINX fleet.

You can navigate to the NGINX One Dashboard view by selecting *Dashboard* under the *Overview* section on the left.

![Dashboard Side Menu](media/lab1-5.png)

You now see a Dashboard view like the example shown below.

![Dashboard View](media/lab1-6.png)

This view provides the following metrics for all NGINX instances.

    | Metric Type | Description |
    | --- | --- |
    | Availability | The overall reachability and availability of your NGINX fleet is displayed here. |
    | NGINX Versions | We can see at a glance what proportion of our fleet is running Plus vs. OSS, and how many instances are running outdated or non-standard versions. |
    | OS Distribution | Similarly, we can see which OSes are part of the fleet. |
    | Certificates | This chart provides insight on expiring certificates that need attention, as well as expired ones that should be removed. |
    | Configuration Recommendations | NGINX One analyzes the configuration files on all of the instances it manages. When a configuration presents a potential security risk or is otherwise not in accordance with best practices, a recommendation is shown. |
    | CVEs | Any CVEs that apply to an instance in your fleet are shown here. |
    | CPU Utilization | The instances with the highest CPU Utilization are shown here for quick visibility into potential performance issues. |
    | Memory Utilization | Top memory consumers are also shown here. |
    | Disk Space Utilization | Along with CPU and memory, instances with the highest disk utilization are shown here to surface possible disk space issues. |
    | Unsuccessful Responses | Instances with the most 4xx or 5xx errors appear here to identify potential attacks, misconfigurations, or upstream application issues. |
    | Network Usage | Top network consumers can help identify targets for optimization. Unusual traffic patterns could potentially indicate an attack attempt. |

**Drilling Down**

Clicking a detail line in any of these charts will let you drill-down and see the instances affected by that particular finding.

![NGINX Drilling Down View](media/lab1-7.png)

---

## Configuration via the Console

In this section, we will leverage NGINX One Console to enable the [stub_status](https://nginx.org/en/docs/http/ngx_http_stub_status_module.html?_ga=2.62776364.1844058681.1724599557-1323320886.1720986347)
location in our **<GetVariable name="nginx-plus-1" />** NGINX instance's configuration.

The stub_status allows users to collect basic metrics about the NGINX instance such as:

- Active connections
- Total number of accepted client connections
- Total number of client requests
- and many more

### Adding a stub_status directive

1. In the NGINX One console, select *Manage* and then *Instances* from the left menu.

1. You should see your **<GetVariable name="nginx-plus-1" />** instance in the list. Click it to view the instance details.

1. Click the *Configuration* link near the top of the instance screen. You will be presented with the configuration editor.

    ![Configuration link](media/lab3-1.png)


#### NGINX Configuration

Now let's take a look at what the **/etc/nginx/nginx.conf** configuration is doing:

    ```nginx
    user  nginx;
    worker_processes  auto;

    error_log  /var/log/nginx/error.log notice;
    pid        /var/run/nginx.pid;

    events {
        worker_connections  1024;
    }
    ```

Let's break down this portion of the NGINX configuration:

**1. *user  nginx;***

This line specifies the user under which NGINX will run as a process. In this case, it's running as the *nginx* user. This is important for security and permission reasons.

When NGINX starts, it needs to bind to certain system resources (e.g., network sockets). By specifying a specific user, we ensure that any processes started by NGINX will run with minimal privileges, reducing the risk of unauthorized access or resource consumption.

**2. worker_processes  auto;**

This line configures how many worker processes NGINX will create to handle incoming requests. The value is set to *auto*, which means that NGINX will automatically determine the optimal number of workers based on the system's capabilities and load.

The *auto* value tells NGINX to:

    * On systems with multiple CPU cores, create a worker process for each core.
    * On systems with a single CPU core, use the system's default maximum process limit (usually 1024).
    * Consider other factors like memory availability and load when deciding on the optimal number of workers.

**3. error_log  /var/log/nginx/error.log notice;**

This line configures how NGINX logs errors that occur during execution. The *notice* level is set, which means that:

    * Errors with a severity level greater than or equal to NOTICE will be logged.
    * Other error levels (e.g., ERROR, WARNING) won't be logged.

The log file location */var/log/nginx/error.log* indicates where NGINX will write its error messages. This is the standard log location for most Linux distributions.

**4. pid /var/run/nginx.pid;**

This line specifies the file path where NGINX will store its process ID (PID). The PID is a unique identifier that allows you to manage and monitor running processes on your system.

In this case, the PID is written to */var/run/nginx.pid*, which is a common location for Linux services like NGINX.

**5. worker_connections 1024;**

This line specifies the maximum number of simultaneous connections a worker process can handle. In this case, it's set to 1024, which means each worker process will be able to accept up to 1024 simultaneous client connections.

    ```nginx
    http {
        include       /etc/nginx/mime.types;
        default_type  application/octet-stream;

        log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                        '$status $body_bytes_sent "$http_referer" '
                        '"$http_user_agent" "$http_x_forwarded_for"';

        access_log  /var/log/nginx/access.log  main;

        sendfile        on;
        #tcp_nopush     on;

        keepalive_timeout  65;

        #gzip  on;

        include /etc/nginx/conf.d/*.conf;
    }
    ```

Here's a brief explanation of this portion of the NGINX configuration:

**HTTP Block**

This block configures how NGINX handles HTTP requests.

**1. include /etc/nginx/mime.types;**

Includes the MIME types file, which maps file extensions to their corresponding content types.

**2. default_type application/octet-stream;**

Specifies the default response type for unknown content types.

**3. log_format main ...**

Defines a custom log format called "main", which logs various request details (e.g., client IP, user agent).

**4. access_log /var/log/nginx/access.log main;**

Enables access logging to the specified file using the defined log format.

**5. sendfile on;**

Enables the sendfile() method for sending files directly from disk to clients, improving performance.

**6. keepalive_timeout 65;**

Sets the keep-alive timeout to 65 seconds, allowing NGINX to maintain connections with clients for a longer period.

**7. include /etc/nginx/conf.d/*.conf;**

Includes all configuration files in the specified directory (e.g., virtual hosts).

Now lets take a look at what the **/etc/nginx/conf.d/default.conf** configuration is doing:

    ```nginx
    server {
        listen       80 default_server;
        server_name  localhost;

        #access_log  /var/log/nginx/host.access.log  main;

        location / {
            root   /usr/share/nginx/html;
            index  index.html index.htm;
        }

        #error_page  404              /404.html;

        # redirect server error pages to the static page /50x.html
        #
        error_page   500 502 503 504  /50x.html;
        location = /50x.html {
            root   /usr/share/nginx/html;
        }
    }
    ```

Here's a brief overview of this NGINX configuration:

**Server Block**

This block configures a single server that listens on port 80 and responds to requests for the domain *localhost*.

- *listen 80 default_server;* specifies that this server should listen on port 80 by default.
- *server_name localhost;* indicates that this server will respond to requests from the domain *localhost*.

**Root Directory and Indexing**

The configuration sets up a single location block that serves files from the */usr/share/nginx/html* directory:

- *root /usr/share/nginx/html;* specifies the root directory for this location.
- *index index.html index.htm;* specifies the default index file to serve when no specific file is requested (in this case, either *index.html* or *index.htm*).

**Error Handling**

The configuration also sets up error handling:

- *error_page 500 502 503 504 /50x.html;* specifies that if any of these specific HTTP errors occur, the client should be redirected to the static page */50x.html*.
- *location = /50x.html* specifies where NGINX can find the error page file.

#### Edit the NGINX Configuration

1. Click the *Edit Configuration* button above the editor.

    ![Edit Configuration link](media/lab3-2.png)

1. Select the **/etc/nginx/conf.d/default.conf** file from the tree view on the left side of the configuration editor.

    ![Select default.conf file](media/lab3-3.png)

1. Edit the selected file to include a location block at the end of the server block with
    the **stub_status** directive. Add the following location block to the server block:

        ```nginx
            location = /nginx_status {
                stub_status;
            }
        ```

    The file should like this (commented out configurations have been removed):

        ```nginx
        server {
            listen       80 default_server;
            server_name  localhost;

            #access_log  /var/log/nginx/host.access.log  main;

            location / {
                root   /usr/share/nginx/html;
                index  index.html index.htm;
            }

            #error_page  404              /404.html;

            # redirect server error pages to the static page /50x.html
            #
            error_page   500 502 503 504  /50x.html;
            location = /50x.html {
                root   /usr/share/nginx/html;
            }

            location = /nginx_status {
                stub_status;
                access_log off;
            }
        }
        ```

1. You will see that there is a message below the editor:

    > *1 recommendation found for /etc/nginx/conf.d/default.conf <br />
        Security - Error: stub_status should have access control list defined*.

    - **Why?** NGINX One includes a configuration advisor and it identified that exposing the **stub_status** endpoint open to the world is considered a security risk.
    - We can remediate this by adding an ACL to the **/nginx_status** location block to only allow our lab environments's local networks and NGINX Agent (running locally on the instance) to access the stub status endpoint.

    ![config warning](media/lab3-4.png)

1. Update that section of the configuration to the following:

        ```nginx
            location /nginx_status {
                stub_status;
                allow 10.0.0.0/8;
                allow 172.18.0.0/16;
                allow 127.0.0.1;
                deny all;
            }
        ```

    Note that the warning should disappear.

1. Click *Next* to display the diff viewer. This view will show you the changes made to the configuration.

    ![Diff viewer](media/lab3-5.png)

1. Click *Save and Publish*. You will see a status message indicating changes are being published, followed by a success message after several seconds.

    ![Publish config pending](media/lab3-6.png)

    ![Publish config success](media/lab3-7.png)

1. Check that the *stub_status* module is working by clicking the *Check* button below.

    <APICheck
        componentName="nginx-plus-1"
        path="/nginx_status"
        targetStatusCode={200}
    />

### Using a TLS certificate

In this section, we will configure our **<GetVariable name="nginx-plus-1" />** NGINX instance to leverage an SSL/TLS certificate.

1. In the NGINX One Console, edit the **/etc/nginx/conf.d/default.conf** file again on the **<GetVariable name="nginx-plus-1" />** instance. Add the following to the server block:

        ```nginx
            listen 443 ssl;
            ssl_certificate /etc/nginx/ssl/wildcard.f5demos.com.crt.pem;
            ssl_certificate_key /etc/nginx/ssl/wildcard.f5demos.com.key.pem;
        ```

1. Click *Next* to display the diff viewer. This view will show you the changes made to the configuration.

    ![Diff viewer](media/lab3-9.png)

1. Click *Save and Publish*. You will see a status message indicating changes are being published, followed by a success message after several seconds.

1. Click the *Details* link on the page. You should now see the certificate, its validity status, expiration date, and subject name.

    ![Details link](media/lab3-10.png)

1. The *details* page will also show a new recommendation. You can view the configuration, and recommendations by clicking the *View Configuration* link in the *Configuration Recommendations* section.

    ![Certificate status](media/lab3-11.png)

1. Select the *default.conf* file from the file picker. Note the blue dots and the number "1" next to default.conf; the configuration viewer highlights the location(s) of any recommendations it has for the NGINX configuration.

    ![Configuration Viewer](media/lab3-12.png)

1. Notice the editor has a "Best Practice" notice indicating that *default_server* should set. Update the configuration to acknowledge this recommendation. <br />&nbsp;<br />The entire **/etc/nginx/conf.d/default.conf** file should now look as follows (commented out configurations have been removed):

        ```nginx
        server {
            listen       80 default_server;
            server_name  localhost;

            listen 443 ssl default_server;
            ssl_certificate /etc/nginx/ssl/wildcard.f5demos.com.crt.pem;
            ssl_certificate_key /etc/nginx/ssl/wildcard.f5demos.com.key.pem;

            #access_log  /var/log/nginx/host.access.log  main;

            location / {
                root   /usr/share/nginx/html;
                index  index.html index.htm;
            }

            #error_page  404              /404.html;

            # redirect server error pages to the static page /50x.html
            #
            error_page   500 502 503 504  /50x.html;
            location = /50x.html {
                root   /usr/share/nginx/html;
            }

            location /nginx_status {
                stub_status;
                allow 10.0.0.0/8;
                allow 172.18.0.0/16;
                allow 127.0.0.1;
                deny all;
            }
        }
        ```

1. Check your work:<br />&nbsp;<br />To check that the <GetVariable name="nginx-plus-1" /> instance is now listening on 443 click the *Check* button below.

    <APICheck
        componentName="nginx-plus-1"
        targetStatusCode={200}
        tlsComponent={true}
    />

## Lab Cleanup

Time to clean up the resources you created in this lab. As a safety precaution, the NGINX One console will not allow you to delete an instance that is online. We will first have to shut down the instances before deleting them from the NGINX One console.


1. For the Docker containers running NGINX run the commands below to stop and remove the container from the NGINX Plus instance in your UDF deployment.

    ``` docker
    docker stop YOUR_CONTAINER_ID
    docker rm YOUR_CONTAINER_ID
    ```

1. In the UDF deployment for this lab, click *Details* for the **NGINX OSS** component.

    ![Select the NGINX component details](media/cleanup-1.png)

1. Click the **Stop** button for this component.

    ![Select the NGINX component details](media/cleanup-2.png)

    > **Note:** You can also remove the nginx-agent running on the NGINX OSS instance using the commands below.

    ```nginx
    sudo apt-get purge nginx-agent
    sudo apt-get autoremove
    sudo apt-get update
    ```

1. From the NGINX One console, in the left-hand menu in the *Manage* section, select *Instances*.

1. Wait until your **<GetVariable name="petname" />*** instances transition into the **Unavailable** state before proceeding. You may need to click the *Refresh* button at the top right of the instance list.

    ![Instance Unavailable](media/cleanup-3.png)

1. For each of your **<GetVariable name="petname" />*** instances, select the *Actions* "..." context menu, and select
    *Delete*.

    > :warning: **Warning:** Make sure you are deleting your own instances and not someone elseâ€™s.

    ![Deleting an instance](media/cleanup-4.png)

1. Confirm the deletion.

    ![Confirming the deletion](media/cleanup-5.png)

1. From the NGINX One console, in the left-hand menu in the *Manage* section, select *Data Plane Keys*.

1. Select the context menu for the Data Plane Key you created in lab 1, and select *Revoke*.

    > :warning: **Warning:** Make sure you are revoking your own key and not someone elseâ€™s.

    ![Revoking a Data Plane Key](media/cleanup-6.png)

1. Confirm the revocation.

    ![Confirming the revocation](media/cleanup-7.png)

## Conclusion

You now completed the interactive lab of adding an NGINX Instance to the NGINX One Console.

The next lab will be a FixIt Lab. [Click here](nginx-one-5.mdx) to proceed to that lab.
